[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the site for the projects of Junho Kook in the Foundation of Data Science class."
  },
  {
    "objectID": "Project2.html",
    "href": "Project2.html",
    "title": "Project2",
    "section": "",
    "text": "ğŸŒ¿ Explanation of Encelia californica, Encelia farinosa, and the Fullerton Arboretum\nEncelia californica, also known as California brittlebush, is a native shrub commonly found in coastal southern California. It has dark green leaves and typically blooms yellow daisy-like flowers. On the other hand, Encelia farinosa, or brittlebush, is native to desert regions and can be recognized by its silvery, fuzzy leaves and similar yellow flowers. While they appear alike from a distance, their leaf texture, color, and natural habitat are key distinguishing features.\nThe Fullerton Arboretum is a botanical garden located on the campus of California State University, Fullerton. It serves as an outdoor classroom and sanctuary for native and exotic plant species, including both Encelia types. Observing these plants in a real-world setting helps students learn the value of biodiversity, field research, and scientific classification.\nIn class, we also worked with the iris dataset, which taught us how quantitative measurements like petal length and width can help distinguish between similar species. This experience parallels our current task of identifying subtle traits between E. californica and E. farinosa.\nâ“ Why does it matter to distinguish between these two species? Being able to distinguish between Encelia californica and Encelia farinosa is important for ecological monitoring, habitat conservation, and understanding plant adaptation. These species thrive in different environmentsâ€”coastal vs.Â desertâ€”and confusing them could lead to incorrect assumptions about climate resilience or ecological balance. Accurate species identification also supports biodiversity preservation and guides sustainable planting decisions in native landscapes."
  },
  {
    "objectID": "Project2.html#motivation-and-context",
    "href": "Project2.html#motivation-and-context",
    "title": "Project2",
    "section": "",
    "text": "ğŸŒ¿ Explanation of Encelia californica, Encelia farinosa, and the Fullerton Arboretum\nEncelia californica, also known as California brittlebush, is a native shrub commonly found in coastal southern California. It has dark green leaves and typically blooms yellow daisy-like flowers. On the other hand, Encelia farinosa, or brittlebush, is native to desert regions and can be recognized by its silvery, fuzzy leaves and similar yellow flowers. While they appear alike from a distance, their leaf texture, color, and natural habitat are key distinguishing features.\nThe Fullerton Arboretum is a botanical garden located on the campus of California State University, Fullerton. It serves as an outdoor classroom and sanctuary for native and exotic plant species, including both Encelia types. Observing these plants in a real-world setting helps students learn the value of biodiversity, field research, and scientific classification.\nIn class, we also worked with the iris dataset, which taught us how quantitative measurements like petal length and width can help distinguish between similar species. This experience parallels our current task of identifying subtle traits between E. californica and E. farinosa.\nâ“ Why does it matter to distinguish between these two species? Being able to distinguish between Encelia californica and Encelia farinosa is important for ecological monitoring, habitat conservation, and understanding plant adaptation. These species thrive in different environmentsâ€”coastal vs.Â desertâ€”and confusing them could lead to incorrect assumptions about climate resilience or ecological balance. Accurate species identification also supports biodiversity preservation and guides sustainable planting decisions in native landscapes."
  },
  {
    "objectID": "Project2.html#main-objective",
    "href": "Project2.html#main-objective",
    "title": "Project2",
    "section": "Main Objective",
    "text": "Main Objective\nThe goal of this project is to practice collecting, analyzing, and interpreting real-world biological data by comparing two similar plant species: Encelia californica and Encelia farinosa. Through field observations and quantitative measurements, we aim to identify distinguishing features between the two species using statistical tools and visualizations in R. This project not only strengthens our understanding of data science concepts like classification and accuracy evaluation, but also emphasizes the practical value of data analysis in environmental and ecological research."
  },
  {
    "objectID": "Project2.html#packages-used-in-this-analysis",
    "href": "Project2.html#packages-used-in-this-analysis",
    "title": "Project2",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(broom)\nlibrary(janitor)\nlibrary(here)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(purrr)\nlibrary(yardstick)\nlibrary(tidyr)\nlibrary(dplyr)\n\n\n\n\nPackage\nUse\n\n\n\n\nhere\nto easily load and save data\n\n\nreadr\nto import the CSV file data\n\n\ndplyr\nto massage and summarize data\n\n\nggplot2\nto create nice-looking and informative graphs\n\n\nrsample\nto split data into training and test sets\n\n\npurrr\nto run the cross-validation\n\n\nyardstick\nto evalute the accuracy of the models\n\n\ntidyr\nto â€œpivotâ€ the predictions data frame so that each row represents 1 model"
  },
  {
    "objectID": "Project2.html#design-and-data-collection",
    "href": "Project2.html#design-and-data-collection",
    "title": "Project2",
    "section": "Design and Data Collection",
    "text": "Design and Data Collection\n\ndf &lt;- read_csv(\"Encelia Classification Data Collection.csv\")\n\nRows: 100 Columns: 5\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Species\ndbl (4): number_rays, disk_diameter, ray_diameter, stem_length\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Randomly sample 200 rows to expand the dataset\nset.seed(42)\ndf_extra &lt;- df %&gt;% sample_n(200, replace = TRUE)\n\ndf_extended &lt;- bind_rows(df, df_extra)\n\ndf_extended\n\n# A tibble: 300 Ã— 5\n   Species number_rays disk_diameter ray_diameter stem_length\n   &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 F                13           1.5          5.5        16  \n 2 F                13           1.5          5.5        19  \n 3 F                11           1.1          3.5         9.3\n 4 F                12           1.4          3.2         4  \n 5 F                11           2            3.7         2.5\n 6 F                 8           1.1          3.5         2.8\n 7 F                13           1.3          4.5        15.5\n 8 F                13           1.5          4.5        11.3\n 9 F                11           1.5          5           9  \n10 F                12           1.5          4.5         7.7\n# â„¹ 290 more rows\n\n\nThe original dataset was collected by manually observing and recording traits of Encelia californica and Encelia farinosa plants at the Fullerton Arboretum. Measurements included the number of rays, disk diameter, ray diameter, and stem length for each plant observed. Since the class activity was limited in duration and scope, only about 100 observations were recorded in total.\nTo build a more robust dataset for analysis and model training, we expanded the original data by randomly sampling from the existing entries to generate a total of 300 rows. This was done using sampling with replacement to preserve the original distribution of traits across both species."
  },
  {
    "objectID": "Project2.html#check-missing-values",
    "href": "Project2.html#check-missing-values",
    "title": "Project2",
    "section": "Check missing values",
    "text": "Check missing values\n\nanyNA(df_extended)\n\n[1] TRUE\n\ncolSums(is.na(df_extended))\n\n      Species   number_rays disk_diameter  ray_diameter   stem_length \n            0             0             0             0            48 \n\n\n\n# Replace NA in numeric columns with column means\ndf_filled &lt;- df_extended %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\ncolSums(is.na(df_filled))\n\n      Species   number_rays disk_diameter  ray_diameter   stem_length \n            0             0             0             0             0 \n\n\nDuring preprocessing, I also checked for missing values in the dataset. Any numeric columns containing missing values were imputed using their respective column means. This ensured that our dataset was complete and ready for statistical analysis and modeling without introducing significant bias or losing too many observations."
  },
  {
    "objectID": "Project2.html#limitations-of-my-data-collection-method",
    "href": "Project2.html#limitations-of-my-data-collection-method",
    "title": "Project2",
    "section": "Limitations of my data collection method",
    "text": "Limitations of my data collection method\nOne limitation of our data collection method was the relatively small sample size and potential measurement inconsistencies due to human error in the field. Additionally, the decision to expand the dataset via random duplication may not accurately reflect real-world biological variation.\nHowever, given time and resource constraints, this approach allowed us to move forward with the analysis while preserving the characteristics of the original observations."
  },
  {
    "objectID": "Project2.html#exploratory-data-analysis",
    "href": "Project2.html#exploratory-data-analysis",
    "title": "Project2",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n# 1. Bar plot: Number of samples per species\nggplot(df_extended, aes(x = Species)) +\n  geom_bar(fill = \"skyblue\") +\n  labs(title = \"Count of Each Species\", x = \"Species\", y = \"Count\")\n\n\n\n\n\n\n\n# 2. Histogram: Distribution of stem length by species\nggplot(df_extended, aes(x = stem_length, fill = Species)) +\n  geom_histogram(alpha = 0.6, position = \"identity\", bins = 30) +\n  labs(title = \"Distribution of Stem Length\", x = \"Stem Length\", y = \"Count\") +\n  theme_minimal()\n\nWarning: Removed 48 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# 3. Scatter plot: Ray diameter vs. disk diameter\nggplot(df_extended, aes(x = disk_diameter, y = ray_diameter, color = Species)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Ray vs. Disk Diameter by Species\",\n       x = \"Disk Diameter\", y = \"Ray Diameter\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 4. Boxplot: Comparing stem length by species\nggplot(df_extended, aes(x = Species, y = stem_length, fill = Species)) +\n  geom_boxplot() +\n  labs(title = \"Stem Length by Species\", x = \"Species\", y = \"Stem Length\") +\n  theme_minimal()\n\nWarning: Removed 48 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nTo better understand the characteristics of Encelia californica (C) and Encelia farinosa (F), I conducted an exploratory data analysis using four types of visualizations.\nFirst, the bar plot shows that the dataset contains a fairly balanced number of observations between the two species, with a slightly higher count for E. farinosa. This balance is crucial for building an effective classification model, such as logistic regression, as it helps avoid model bias toward the majority class.\nSecond, the histogram of stem length reveals a clear distinction between species. E. californica tends to have longer stems with a wider spread, whereas E. farinosa shows a concentration of shorter stem lengths. This indicates that stem length could be a strong predictor in the classification model.\nThird, the scatter plot comparing disk diameter and ray diameter shows moderate clustering by species. While there is some overlap, the patterns suggest that a combination of these two features could help distinguish the species when used together in a multivariable model.\nLastly, the boxplot further supports the finding that E. californica generally has longer stems, with a higher median and greater variability compared to E. farinosa. Outliers are also present for E. californica, which may reflect natural variation in its growth or data entry noise.\n\n# Calculate Q1, Q3, and IQR for stem_length\nQ1 &lt;- quantile(df_extended$stem_length, 0.25, na.rm = TRUE)\nQ3 &lt;- quantile(df_extended$stem_length, 0.75, na.rm = TRUE)\nIQR_value &lt;- Q3 - Q1\n\n# Define lower and upper bounds for outliers\nlower_bound &lt;- Q1 - 1.5 * IQR_value\nupper_bound &lt;- Q3 + 1.5 * IQR_value\n\n# Print thresholds (optional)\ncat(\"Lower Bound:\", lower_bound, \"| Upper Bound:\", upper_bound, \"\\n\")\n\nLower Bound: -14.3125 | Upper Bound: 43.7875 \n\n# Filter out rows where stem_length is an outlier\ndf_no_outliers &lt;- df_extended %&gt;%\n  filter(stem_length &gt;= lower_bound & stem_length &lt;= upper_bound)\n\n# Check how many rows were removed\nn_removed &lt;- nrow(df_extended) - nrow(df_no_outliers)\ncat(\"Number of outliers removed:\", n_removed, \"\\n\")\n\nNumber of outliers removed: 52 \n\n\nDuring the exploratory data analysis, we identified potential outliers in the stem_length variable, particularly among samples of Encelia californica. These outliers were visually evident in the boxplot, showing values that extended far beyond the typical range of the data.\nTo address this, we applied the interquartile range (IQR) method to detect and remove extreme values. Specifically, any observations with stem length values falling below Q1 âˆ’ 1.5 Ã— IQR or above Q3 + 1.5 Ã— IQR were considered outliers and excluded from the dataset. As a result, a small number of data points were removed, allowing us to reduce the influence of extreme values that could potentially skew the model."
  },
  {
    "objectID": "Project2.html#training-test-split",
    "href": "Project2.html#training-test-split",
    "title": "Project2",
    "section": "Training-Test Split",
    "text": "Training-Test Split\n\nset.seed(123)\n\n# Split the data (80% training, 20% testing)\ndata_split &lt;- initial_split(df_no_outliers, prop = 0.8, strata = Species)\n\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\nnrow(train_data)\n\n[1] 197\n\nnrow(test_data)\n\n[1] 51\n\n\nThe training set is used to fit the logistic regression model, allowing it to learn patterns and relationships between the predictor variables and the species classification. The test set, which the model has never seen during training, is then used to evaluate how well the model performs on new, unseen data.\nThis separation helps prevent overfitting â€” where the model performs very well on the training data but poorly on new data. By evaluating model performance on the test set, we can estimate how well the model will generalize to other real-world cases."
  },
  {
    "objectID": "Project2.html#modeling",
    "href": "Project2.html#modeling",
    "title": "Project2",
    "section": "Modeling",
    "text": "Modeling\n\n# Make sure species is a factor and set reference level\ntrain_data &lt;- train_data %&gt;%\n  mutate(Species = factor(Species, levels = c(\"C\", \"F\")))\n\ntest_data &lt;- test_data %&gt;%\n  mutate(Species = factor(Species, levels = c(\"C\", \"F\")))\n\n\n# Cross-validation folds\ncv_folds &lt;- vfold_cv(train_data, v = 5, strata = Species)\n\n\n# Define candidate models\nmodel1 &lt;- Species ~ stem_length\nmodel2 &lt;- Species ~ ray_diameter + disk_diameter\nmodel3 &lt;- Species ~ number_rays + ray_diameter + disk_diameter + stem_length\n\n\nfit_model &lt;- function(formula, folds) {\n  folds %&gt;%\n    mutate(\n      model = map(splits, ~ tryCatch(\n        glm(formula, data = analysis(.x), family = \"binomial\"),\n        error = function(e) NULL\n      )),\n      pred = map2(model, splits, ~ {\n        if (!is.null(.x)) {\n          augment(.x, newdata = assessment(.y), type.predict = \"response\")\n        } else {\n          NULL\n        }\n      }),\n      truth = map(splits, ~ assessment(.x)$Species)\n    )\n}\n\n\n# Evaluate each model\nget_accuracy &lt;- function(results) {\n  results %&gt;%\n    mutate(\n      pred_class = map(pred, ~ if (!is.null(.x)) if_else(.x$.fitted &gt; 0.5, \"F\", \"C\") else NULL),\n      truth = map(truth, ~ as.character(.x)),\n      metrics = map2(pred_class, truth, ~ {\n        if (!is.null(.x) && !is.null(.y)) {\n          accuracy_vec(\n            truth = factor(.y, levels = c(\"C\", \"F\")),\n            estimate = factor(.x, levels = c(\"C\", \"F\"))\n          )\n        } else {\n          NA\n        }\n      })\n    ) %&gt;%\n    unnest(metrics) %&gt;%\n    filter(!is.na(metrics)) %&gt;%\n    rename(accuracy = metrics)\n}\n\n# Fit each model using cross-validation\ncv_results1 &lt;- fit_model(model1, cv_folds)\ncv_results2 &lt;- fit_model(model2, cv_folds)\ncv_results3 &lt;- fit_model(model3, cv_folds)\n\n\nacc1 &lt;- get_accuracy(cv_results1)\nacc2 &lt;- get_accuracy(cv_results2)\nacc3 &lt;- get_accuracy(cv_results3)\n\n# Mean accuracy\nmean(acc1$accuracy, na.rm = TRUE)\n\n[1] 0.7967341\n\nmean(acc2$accuracy, na.rm = TRUE)\n\n[1] 0.762004\n\nmean(acc3$accuracy, na.rm = TRUE)\n\n[1] 0.9342173\n\n\nPropose several logistic regression models and use cross-validation to select a best model, following the steps in the â€œCross-Validation (Part 3)â€ video and the â€œModel Selection for Logistic Regressionâ€ activity.\n\nWhat is logistic regression? Why are you doing it? Logistic regression is a classification method used to predict a binary outcome using one or more predictor variables. In this case, I am using it to classify whether a plant is Encelia californica (C) or Encelia farinosa (F) based on features like stem length, ray diameter, and disk diameter.\nWhy did you choose each model that you are considering? I began with a simple model using only stem_length, then added additional predictors such as ray_diameter and disk_diameter. The third model included all available numerical variables. This progression allows to balance simplicity and performance.\nWhy are you using cross-validation? How does it work? Cross-validation helps evaluate model performance more reliably by splitting the training data into folds. The model is trained on some folds and tested on others, cycling through all combinations. This reduces the risk of overfitting and gives a more general estimate of how the model will perform on unseen data.\nWhich model are you selecting as the best model? Why? The final model was evaluated on the test set, and it achieved an accuracy of approximately 93%. This suggests the model generalizes well and can reliably classify the two Encelia species using field measurements."
  },
  {
    "objectID": "Project2.html#insights",
    "href": "Project2.html#insights",
    "title": "Project2",
    "section": "Insights",
    "text": "Insights\nTo evaluate the predictive performance of the final logistic regression model, I visualized both the modelâ€™s accuracy and the specific flowers it misclassified.\n\n# Step 1: Fit final logistic regression model\nfinal_model &lt;- glm(Species ~ number_rays + ray_diameter + disk_diameter + stem_length,\n                   data = train_data, family = \"binomial\")\n\n# Step 2: Predict probabilities and classify\nfinal_pred &lt;- test_data %&gt;%\n  mutate(\n    fitted_prob = predict(final_model, newdata = test_data, type = \"response\"),\n    pred_class = if_else(fitted_prob &gt; 0.5, \"F\", \"C\"),\n    truth = Species\n  )\n\nfinal_pred &lt;- final_pred %&gt;%\n  mutate(\n    truth = factor(truth, levels = c(\"C\", \"F\")),\n    pred_class = factor(pred_class, levels = c(\"C\", \"F\"))\n  )\n\n# Create confusion matrix\nconf_mat_tbl &lt;- conf_mat(final_pred, truth = truth, estimate = pred_class)\nautoplot(conf_mat_tbl, type = \"heatmap\")\n\n\n\n\n\n\n\n\nI created a confusion matrix to compare the modelâ€™s predicted species labels with the actual species in the test set. This matrix provides a clear view of how many flowers were classified correctly and where the model made mistakes. The confusion matrix heatmap revealed that most of the predictions were correct, with only a few misclassified flowers.\n\n# Scatter plot of prediction results\nlibrary(ggplot2)\n\nggplot(final_pred, aes(x = ray_diameter, y = stem_length, color = pred_class, shape = truth)) +\n  geom_point(size = 3, alpha = 0.8) +\n  labs(title = \"Model Predictions vs Actual Species\",\n       x = \"Ray Diameter\", y = \"Stem Length\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nTo better understand which flowers were incorrectly predicted and why, I visualized the relationship between stem length and ray diameterâ€”two features the model used for prediction.\nIn this scatter plot, points where the predicted species (pred_class) differs from the actual species (truth) can be identified by mismatched color and shape. Most of the misclassifications occurred where the feature values of E. californica and E. farinosa overlapâ€”especially when E. californica had unusually short stem lengths or smaller ray diameters, making them resemble E. farinosa based on the modelâ€™s learned patterns.\nQ. Which flowers (if any) were incorrectly predicted? Why do you suspect that they were incorrectly predicted?\nâ€“&gt; I suspect that these misclassifications were due to natural overlap in morphological characteristics between the two species. Additionally, some measurement noise or human error during data collection might have affected the clarity of class boundaries. Because logistic regression assumes a linear decision boundary, it may also struggle to correctly classify borderline cases where nonlinear relationships exist."
  },
  {
    "objectID": "Project1.html",
    "href": "Project1.html",
    "title": "Project1",
    "section": "",
    "text": "Analysis of the Relationship between Loan Availability and Local Rent"
  },
  {
    "objectID": "Project1.html#subject",
    "href": "Project1.html#subject",
    "title": "Project1",
    "section": "",
    "text": "Analysis of the Relationship between Loan Availability and Local Rent"
  },
  {
    "objectID": "Project1.html#main-objective",
    "href": "Project1.html#main-objective",
    "title": "Project1",
    "section": "Main Objective",
    "text": "Main Objective\nIt analyzes how high rents in certain areas affect loan approval rates and insolvency rates to provide insights into financial-real estate linkage risks and financial product design."
  },
  {
    "objectID": "Project1.html#packages-used-in-this-analysis",
    "href": "Project1.html#packages-used-in-this-analysis",
    "title": "Project1",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\n# Data Wrangling\nlibrary(tidyverse)      \n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.5.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.4     âœ” tidyr     1.3.1\nâœ” purrr     1.0.4     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)         \nlibrary(janitor)       \n\nWarning: package 'janitor' was built under R version 4.3.3\n\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(lubridate)     \n\n# Exploratory Data Analysis\nlibrary(ggplot2)        \nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.3.3\n\n\ncorrplot 0.95 loaded\n\nlibrary(reshape2)\n\n\nAttaching package: 'reshape2'\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nlibrary(skimr)          \n\n# Model Prediction\nlibrary(caret)          \n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(glmnet)         \n\nWarning: package 'glmnet' was built under R version 4.3.3\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.3.3\n\n\nrandomForest 4.7-1.2\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: 'randomForest'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nThe following object is masked from 'package:ggplot2':\n\n    margin"
  },
  {
    "objectID": "Project1.html#used-data",
    "href": "Project1.html#used-data",
    "title": "Project1",
    "section": "Used Data",
    "text": "Used Data\nFor this project, I will use three main data files:\n\nloans_OC.csv: Contains loan data from Orange County.\nSoCalRent1.csv and SoCalRent2.csv: Contain rental data from Southern California, including various regions.\n\nThese datasets will be combined and analyzed to explore the relationship between regional rental prices and loan approval outcomes."
  },
  {
    "objectID": "Project1.html#data-wrangling",
    "href": "Project1.html#data-wrangling",
    "title": "Project1",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n# Read data\nloans &lt;- read_csv(\"loans_OC.csv\") %&gt;% clean_names()\n\nRows: 24472 Columns: 18\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (8): institution, census_tract, ethnicity, race, sex, residency_type, ci...\ndbl (9): loan_amount, property_value, interest_rate, total_loan_costs, incom...\nlgl (1): applicant_over_62\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrent1 &lt;- read_csv(\"SoCalRent1.csv\") %&gt;% clean_names()\n\nRows: 183 Columns: 7\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (3): City, Type, Location\ndbl (4): Price, Beds, Baths, SqFt\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrent2 &lt;- read_csv(\"SoCalRent2.csv\") %&gt;% clean_names()\n\nRows: 117 Columns: 7\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (3): City, Type, Location\ndbl (4): Price, Beds, Baths, SqFt\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Combine rent datasets\nrent &lt;- bind_rows(rent1, rent2)\n\nWhen looking at the data, there were missing values, so it was imputed and processed up to outliers.\nRemoves any row in loans or rent where 50% or more of the values are missing. Rows with too many missing values may not be useful for analysis, and imputing them could introduce bias or noise. It is safer to drop them before further processing.\n\n# Remove rows with too many missing values\nloans &lt;- loans %&gt;%\n  filter(rowSums(is.na(.)) / ncol(.) &lt; 0.5)\n\nrent &lt;- rent %&gt;%\n  filter(rowSums(is.na(.)) / ncol(.) &lt; 0.5)\n\n# Impute missing values\nloans &lt;- loans %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\nrent &lt;- rent %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\n# Identify and remove outliers (IQR method)\nremove_outliers &lt;- function(df, col) {\n  if (!col %in% names(df)) {\n    warning(paste(\"Column\", col, \"not found in dataframe.\"))\n    return(df)\n  }\n  \n  non_na_values &lt;- df[[col]][!is.na(df[[col]])]\n  \n  if (length(non_na_values) == 0) {\n    warning(paste(\"No non-NA values in column\", col))\n    return(df)\n  }\n  \n  Q1 &lt;- quantile(non_na_values, 0.25)\n  Q3 &lt;- quantile(non_na_values, 0.75)\n  IQR &lt;- Q3 - Q1\n\n  lower &lt;- Q1 - 1.5 * IQR\n  upper &lt;- Q3 + 1.5 * IQR\n  \n  df %&gt;%\n    filter(.data[[col]] &gt;= lower & .data[[col]] &lt;= upper)\n}\n\n\nloans &lt;- remove_outliers(loans, \"loan_amount\")\nrent &lt;- remove_outliers(rent, \"rent\")\n\nWarning in remove_outliers(rent, \"rent\"): Column rent not found in dataframe.\n\n# Inspect data\nskim(loans)\n\n\nData summary\n\n\nName\nloans\n\n\nNumber of rows\n22127\n\n\nNumber of columns\n18\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nlogical\n1\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ninstitution\n0\n1.00\n4\n40\n0\n73\n0\n\n\ncensus_tract\n113\n0.99\n6\n6\n0\n577\n0\n\n\nethnicity\n0\n1.00\n5\n22\n0\n3\n0\n\n\nrace\n0\n1.00\n5\n16\n0\n7\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n3\n0\n\n\nresidency_type\n0\n1.00\n17\n19\n0\n3\n0\n\n\ncity\n3470\n0.84\n4\n22\n0\n40\n0\n\n\naction\n0\n1.00\n8\n12\n0\n2\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\napplicant_over_62\n6\n1\n0.12\nFAL: 19515, TRU: 2606\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nloan_amount\n0\n1\n648605.10\n263547.59\n5000.00\n475000.00\n645000.00\n815000.00\n1345000.00\nâ–‚â–†â–‡â–ƒâ–‚\n\n\nproperty_value\n0\n1\n922739.98\n402922.44\n15000.00\n665000.00\n865000.00\n1125404.84\n5305000.00\nâ–‡â–ƒâ–â–â–\n\n\ninterest_rate\n0\n1\n3.09\n0.63\n0.75\n2.81\n3.00\n3.20\n11.60\nâ–†â–‡â–â–â–\n\n\ntotal_loan_costs\n0\n1\n7463.89\n3979.26\n0.00\n5520.00\n7016.94\n7978.05\n57545.50\nâ–‡â–â–â–â–\n\n\nincome\n0\n1\n194.04\n255.45\n-245.00\n109.00\n155.00\n230.00\n24160.00\nâ–‡â–â–â–â–\n\n\ntract_population\n0\n1\n6104.30\n3397.67\n0.00\n4242.00\n5539.00\n7089.00\n22185.00\nâ–ƒâ–‡â–â–â–\n\n\ntract_minority_population_percent\n0\n1\n49.38\n21.23\n0.00\n33.33\n45.79\n66.17\n99.68\nâ–‚â–‡â–†â–…â–‚\n\n\ntract_to_msa_income_percentage\n0\n1\n113.54\n45.88\n0.00\n83.00\n117.00\n146.00\n289.00\nâ–‚â–‡â–‡â–â–\n\n\ntract_housing_median_age\n0\n1\n34.35\n15.63\n0.00\n24.00\n39.00\n46.00\n74.00\nâ–ƒâ–ƒâ–‡â–†â–\n\n\n\n\nskim(rent)\n\n\nData summary\n\n\nName\nrent\n\n\nNumber of rows\n300\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncity\n0\n1\n4\n22\n0\n74\n0\n\n\ntype\n0\n1\n5\n5\n0\n2\n0\n\n\nlocation\n0\n1\n2\n2\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nprice\n0\n1\n3711.27\n1733.90\n950\n2800\n3395\n4000\n20000.0\nâ–‡â–â–â–â–\n\n\nbeds\n0\n1\n3.00\n0.96\n1\n2\n3\n4\n6.0\nâ–†â–‡â–…â–â–\n\n\nbaths\n0\n1\n2.29\n0.80\n1\n2\n2\n3\n6.5\nâ–‡â–†â–â–â–\n\n\nsq_ft\n0\n1\n1633.31\n726.99\n500\n1120\n1454\n1968\n6361.0\nâ–‡â–…â–â–â–\n\n\n\n\n\n\n# Check missing values\nloans %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 Ã— 18\n  institution census_tract ethnicity  race   sex residency_type loan_amount\n        &lt;int&gt;        &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;       &lt;int&gt;\n1           0          113         0     0     0              0           0\n# â„¹ 11 more variables: property_value &lt;int&gt;, interest_rate &lt;int&gt;,\n#   total_loan_costs &lt;int&gt;, income &lt;int&gt;, applicant_over_62 &lt;int&gt;,\n#   tract_population &lt;int&gt;, tract_minority_population_percent &lt;int&gt;,\n#   tract_to_msa_income_percentage &lt;int&gt;, tract_housing_median_age &lt;int&gt;,\n#   city &lt;int&gt;, action &lt;int&gt;\n\nrent %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 Ã— 7\n   city price  beds baths sq_ft  type location\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n1     0     0     0     0     0     0        0\n\n\nMissing values for non-dimensional variables such as census_tract were not imputed. In addition, since the analysis does not use the variable for modeling or calculation, we decided that it doesnâ€™t matter if there are missing values.\nThis code transforms two separate datasets (loan and rent) into aggregated city-level summaries and merges them into a single dataset. This merged dataset is ready for exploratory data analysis (EDA) and modeling to study the relationship between loan approval rates and rental market factors across cities.\n\n# Aggregate loans data by City\nloans_city_summary &lt;- loans %&gt;%\n  group_by(city) %&gt;%\n  summarise(\n    approval_rate = mean(action == \"Approved\", na.rm = TRUE),\n    avg_loan_amount = mean(loan_amount, na.rm = TRUE),\n    avg_income = mean(income, na.rm = TRUE),\n    count_loans = n()\n  ) %&gt;%\n  ungroup()\n\n\n# Aggregate rent data by City\nrent_summary &lt;- rent %&gt;%\n  group_by(city) %&gt;%\n  summarise(\n    avg_rent = mean(price, na.rm = TRUE),\n    avg_sqft = mean(sq_ft, na.rm = TRUE),\n    count_rentals = n()\n  ) %&gt;%\n  ungroup()\n\n\n# merge (inner join: only common city)\ncombined &lt;- inner_join(loans_city_summary, rent_summary, by = \"city\")\n\nprint(head(combined))\n\n# A tibble: 6 Ã— 8\n  city    approval_rate avg_loan_amount avg_income count_loans avg_rent avg_sqft\n  &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;      &lt;dbl&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Aliso â€¦         0.944         586512.       168.         516    3420     1252.\n2 Anaheim         0.861         578890.       160.        1789    3716.    1227.\n3 Brea            0.821         505247.       151.         324    2575     1280 \n4 Buena â€¦         0.899         554760.       143.         416    3125     1439 \n5 Costa â€¦         0.883         741845.       243.         580    4025.    1338.\n6 Cypress         0.903         595583.       152.         309    5600     1724 \n# â„¹ 1 more variable: count_rentals &lt;int&gt;"
  },
  {
    "objectID": "Project1.html#explore-combined-data",
    "href": "Project1.html#explore-combined-data",
    "title": "Project1",
    "section": "Explore combined data",
    "text": "Explore combined data\n\nskim(combined)\n\n\nData summary\n\n\nName\ncombined\n\n\nNumber of rows\n30\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncity\n0\n1\n4\n22\n0\n30\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\napproval_rate\n0\n1\n0.88\n0.05\n0.72\n0.86\n0.89\n0.91\n0.95\nâ–â–â–…â–‡â–†\n\n\navg_loan_amount\n0\n1\n635642.76\n103182.04\n399558.40\n580795.74\n639746.87\n697175.06\n933043.48\nâ–‚â–…â–‡â–‚â–\n\n\navg_income\n0\n1\n188.56\n48.29\n113.81\n157.34\n181.10\n211.95\n305.88\nâ–ƒâ–‡â–ƒâ–â–‚\n\n\ncount_loans\n0\n1\n559.00\n402.55\n46.00\n291.00\n470.50\n751.25\n1789.00\nâ–‡â–…â–ƒâ–â–\n\n\navg_rent\n0\n1\n3909.98\n1242.70\n1550.00\n3031.25\n3707.78\n4332.92\n7030.57\nâ–â–‡â–…â–‚â–\n\n\navg_sqft\n0\n1\n1568.45\n669.47\n930.00\n1137.96\n1309.12\n1831.00\n4300.00\nâ–‡â–…â–â–â–\n\n\ncount_rentals\n0\n1\n4.97\n5.02\n1.00\n1.25\n3.00\n7.00\n24.00\nâ–‡â–‚â–â–â–"
  },
  {
    "objectID": "Project1.html#eda-with-visualization",
    "href": "Project1.html#eda-with-visualization",
    "title": "Project1",
    "section": "EDA with Visualization",
    "text": "EDA with Visualization\nThese three visualizations work together to provide: - A matrix view of correlations between key variables. - A focused scatter plot for the relationship of rent vs approval rate. - A summary of the approval rate distribution across the dataset.\nğŸ‘‰ They support exploratory data analysis (EDA) by uncovering patterns and potential relationships before modeling.\n\n# correlation matrix\ncor_matrix &lt;- combined %&gt;%\n  select(approval_rate, avg_rent, avg_loan_amount, avg_income, avg_sqft) %&gt;%\n  cor(use = \"complete.obs\")\n\ncor_melted &lt;- melt(cor_matrix)\n\nggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +\n  geom_tile() +\n  geom_text(aes(label = round(value, 2)), color = \"white\", size = 4) +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0) +\n  labs(title = \"Correlation Heatmap\",\n       x = \"\",\n       y = \"\",\n       fill = \"Correlation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Scatter plot: Average rent vs approval rate\nggplot(combined, aes(x = avg_rent, y = approval_rate)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Average Rent vs Loan Approval Rate\",\n       x = \"Average Rent\",\n       y = \"Approval Rate\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# 3. Distribution of approval_rate\nggplot(combined, aes(x = approval_rate)) +\n  geom_histogram(bins = 20, fill = \"skyblue\") +\n  labs(title = \"Distribution of Loan Approval Rate\", x = \"Approval Rate\", y = \"Count\")\n\n\n\n\n\n\n\n\nğŸ‘‰ From these results, it appears that the loan approval rate is relatively high across most cities and shows weak correlation with average rent, average income, and property size. However, strong multicollinearity is observed among the predictor variables.\nğŸ‘‰ Given these findings, I plan to proceed with regression modeling to formally test the statistical significance and predictive power of average rent, income, and loan amount on the approval rate, despite the low correlations observed.\nğŸ‘‰ I also intend to explore alternative models such as regularized regression (LASSO) to address multicollinearity and assess variable importance, and non-linear models (e.g., random forest) to capture any non-linear effects that may not be visible in the scatter plot.\nThe exploratory data analysis shows weak correlations between loan approval rate and predictors such as average rent and income, while strong correlations are present among the predictors themselves. Therefore, we plan to use linear regression, LASSO, and random forest models to further investigate the relationship. Perhaps the predictive performance of the random forest model, which is less affected by multicollinearity, is expected to be the best."
  },
  {
    "objectID": "Project1.html#predictive-modeling",
    "href": "Project1.html#predictive-modeling",
    "title": "Project1",
    "section": "Predictive Modeling",
    "text": "Predictive Modeling\n\n# Select key variables\nmodel_data &lt;- combined %&gt;%\n  select(approval_rate, avg_rent, avg_income, avg_sqft) %&gt;%\n  na.omit()  # remove missing values\n\n# Split into training (80%) and testing (20%) sets\nset.seed(123)\ntrain_index &lt;- createDataPartition(model_data$approval_rate, p = 0.8, list = FALSE)\ntrain_data &lt;- model_data[train_index, ]\ntest_data &lt;- model_data[-train_index, ]\n\n\n# Set up cross-validation\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 5,\n  summaryFunction = defaultSummary\n)\n\n\n# Load libraries\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.3.3\n\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.3.0 â”€â”€\n\n\nâœ” broom        1.0.7     âœ” rsample      1.2.1\nâœ” dials        1.4.0     âœ” tune         1.3.0\nâœ” infer        1.0.7     âœ” workflows    1.2.0\nâœ” modeldata    1.4.0     âœ” workflowsets 1.1.0\nâœ” parsnip      1.3.1     âœ” yardstick    1.3.2\nâœ” recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.3.3\n\n\nWarning: package 'dials' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.3\n\n\nWarning: package 'modeldata' was built under R version 4.3.3\n\n\nWarning: package 'parsnip' was built under R version 4.3.3\n\n\nWarning: package 'recipes' was built under R version 4.3.3\n\n\nWarning: package 'tune' was built under R version 4.3.3\n\n\nWarning: package 'workflows' was built under R version 4.3.3\n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– randomForest::combine()  masks dplyr::combine()\nâœ– scales::discard()        masks purrr::discard()\nâœ– Matrix::expand()         masks tidyr::expand()\nâœ– dplyr::filter()          masks stats::filter()\nâœ– recipes::fixed()         masks stringr::fixed()\nâœ– dplyr::lag()             masks stats::lag()\nâœ– caret::lift()            masks purrr::lift()\nâœ– randomForest::margin()   masks ggplot2::margin()\nâœ– Matrix::pack()           masks tidyr::pack()\nâœ– yardstick::precision()   masks caret::precision()\nâœ– yardstick::recall()      masks caret::recall()\nâœ– yardstick::sensitivity() masks caret::sensitivity()\nâœ– yardstick::spec()        masks readr::spec()\nâœ– yardstick::specificity() masks caret::specificity()\nâœ– recipes::step()          masks stats::step()\nâœ– Matrix::unpack()         masks tidyr::unpack()\nâœ– recipes::update()        masks Matrix::update(), stats::update()\n\n# 1ï¸âƒ£ Recipe\nloan_recipe &lt;- recipe(approval_rate ~ ., data = train_data) %&gt;%\n  step_normalize(all_predictors())\n\n# 2ï¸âƒ£ Model specifications\nlm_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\")\n\nrf_spec &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%  # mixture=1 for LASSO\n  set_engine(\"glmnet\")\n\n# 3ï¸âƒ£ Workflow\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(lm_spec)\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(rf_spec)\n\nlasso_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(lasso_spec)\n\n# 4ï¸âƒ£ Cross-validation\nset.seed(123)\ncv_folds &lt;- vfold_cv(train_data, v = 5)\n\n# 5ï¸âƒ£ Fit models\nlm_res &lt;- lm_wf %&gt;% fit_resamples(resamples = cv_folds, metrics = metric_set(rmse, rsq))\nrf_res &lt;- rf_wf %&gt;% fit_resamples(resamples = cv_folds, metrics = metric_set(rmse, rsq))\n\nWarning: package 'ranger' was built under R version 4.3.3\n\nlasso_res &lt;- lasso_wf %&gt;% tune_grid(\n  resamples = cv_folds,\n  grid = grid_regular(penalty(), levels = 10),\n  metrics = metric_set(rmse, rsq)\n)\n\nâ†’ A | warning: A correlation computation is required, but `estimate` is constant and has 0\n               standard deviation, resulting in a divide by 0 error. `NA` will be returned.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x5\n\n\n\n\n# 6ï¸âƒ£ Collect metrics\ncollect_metrics(lm_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0620     5  0.0162 Preprocessor1_Model1\n2 rsq     standard   0.115      5  0.0776 Preprocessor1_Model1\n\ncollect_metrics(rf_res)\n\n# A tibble: 2 Ã— 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0454     5 0.00842 Preprocessor1_Model1\n2 rsq     standard   0.181      5 0.0639  Preprocessor1_Model1\n\ncollect_metrics(lasso_res)\n\n# A tibble: 20 Ã— 7\n         penalty .metric .estimator     mean     n std_err .config              \n           &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 0.0000000001  rmse    standard     0.0618     5  0.0162 Preprocessor1_Model01\n 2 0.0000000001  rsq     standard     0.116      5  0.0777 Preprocessor1_Model01\n 3 0.00000000129 rmse    standard     0.0618     5  0.0162 Preprocessor1_Model02\n 4 0.00000000129 rsq     standard     0.116      5  0.0777 Preprocessor1_Model02\n 5 0.0000000167  rmse    standard     0.0618     5  0.0162 Preprocessor1_Model03\n 6 0.0000000167  rsq     standard     0.116      5  0.0777 Preprocessor1_Model03\n 7 0.000000215   rmse    standard     0.0618     5  0.0162 Preprocessor1_Model04\n 8 0.000000215   rsq     standard     0.116      5  0.0777 Preprocessor1_Model04\n 9 0.00000278    rmse    standard     0.0618     5  0.0162 Preprocessor1_Model05\n10 0.00000278    rsq     standard     0.116      5  0.0777 Preprocessor1_Model05\n11 0.0000359     rmse    standard     0.0618     5  0.0162 Preprocessor1_Model06\n12 0.0000359     rsq     standard     0.117      5  0.0776 Preprocessor1_Model06\n13 0.000464      rmse    standard     0.0602     5  0.0155 Preprocessor1_Model07\n14 0.000464      rsq     standard     0.122      5  0.0764 Preprocessor1_Model07\n15 0.00599       rmse    standard     0.0498     5  0.0115 Preprocessor1_Model08\n16 0.00599       rsq     standard     0.276      2  0.173  Preprocessor1_Model08\n17 0.0774        rmse    standard     0.0449     5  0.0113 Preprocessor1_Model09\n18 0.0774        rsq     standard   NaN          0 NA      Preprocessor1_Model09\n19 1             rmse    standard     0.0449     5  0.0113 Preprocessor1_Model10\n20 1             rsq     standard   NaN          0 NA      Preprocessor1_Model10\n\nfinal_lm &lt;- lm_wf %&gt;% fit(data = train_data)\nfinal_rf &lt;- rf_wf %&gt;% fit(data = train_data)\nfinal_lasso &lt;- lasso_wf %&gt;%\n  finalize_workflow(select_best(lasso_res)) %&gt;%  # lassoëŠ” best tuning ê°’ ì‚¬ìš©\n  fit(data = train_data)\n\nWarning in select_best(lasso_res): No value of `metric` was given; \"rmse\" will\nbe used.\n\n\n\n# Make predictions and evaluate performance\nlm_pred &lt;- predict(final_lm, new_data = test_data)\nrf_pred &lt;- predict(final_rf, new_data = test_data)\nlasso_pred &lt;- predict(final_lasso, new_data = test_data)\n\nlm_perf &lt;- postResample(pred = lm_pred, obs = test_data$approval_rate)\nrf_perf &lt;- postResample(pred = rf_pred, obs = test_data$approval_rate)\nlasso_perf &lt;- postResample(pred = lasso_pred, obs = test_data$approval_rate)\n\n\n# Compare model performance\nresults &lt;- data.frame(\n  Model = c(\"Linear Regression\", \"Random Forest\", \"LASSO\"),\n  RMSE = c(lm_perf[\"RMSE\"], rf_perf[\"RMSE\"], lasso_perf[\"RMSE\"]),\n  Rsquared = c(lm_perf[\"Rsquared\"], rf_perf[\"Rsquared\"], lasso_perf[\"Rsquared\"])\n)\n\nprint(\"Model Performance Comparison:\")\n\n[1] \"Model Performance Comparison:\"\n\nprint(results)\n\n              Model       RMSE  Rsquared\n1 Linear Regression 0.03938614 0.3498441\n2     Random Forest 0.03139006 0.3886215\n3             LASSO 0.03806624        NA\n\n\nAs expected, the R squared value showed the best performance of the random forest model, which could be selected as the final model.\n\n# Plot variable importance (Random Forest)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nvip(final_rf)\n\n\n\n\n\n\n\n\nThe variable that most influenced the prediction was identified as avg_income."
  },
  {
    "objectID": "Project1.html#significance-of-the-project",
    "href": "Project1.html#significance-of-the-project",
    "title": "Project1",
    "section": "Significance of the Project",
    "text": "Significance of the Project\nThis project integrates loan data and rental market data at the city level to explore potential relationships between loan approval rates and local housing characteristics.By combining and analyzing these datasets, we aim to uncover patterns that may not be visible from loan data or rental data alone.\nThrough data cleaning, transformation, exploratory data analysis (EDA), and predictive modeling, the project demonstrates a complete data science pipeline from raw data to actionable insights."
  },
  {
    "objectID": "Project1.html#key-insights-breaking-points",
    "href": "Project1.html#key-insights-breaking-points",
    "title": "Project1",
    "section": "Key Insights & Breaking points",
    "text": "Key Insights & Breaking points\nIt was discovered that average income was the predictor that had the greatest impact on the loan approval rate.\nHowever, it was difficult to maximize the modelâ€™s performance due to the small number of variables and data, suggesting that additional factors such as credit scores and debt ratios were needed. In addition, if the multicollinearity problem, which reveals a strong correlation between predictors, has been solved, better performance can be expected in the linear regression model."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSUF_DS",
    "section": "",
    "text": "Hello everyone. Iâ€™m Junho Kook, an exchange student from South Korea. I did my best to prepare it even though it has linguistic barriers and Iâ€™m new to the R project."
  }
]