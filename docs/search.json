[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the site for the projects of Junho Kook in the Foundation of Data Science class."
  },
  {
    "objectID": "Project2.html",
    "href": "Project2.html",
    "title": "Project2",
    "section": "",
    "text": "Write a few sentences about Encelia californica, Encelia farinosa, and the Fullerton Arboretum. You may also discuss what you learned about the iris dataset.\nWhy should someone care about being able to distinguish between these two species?"
  },
  {
    "objectID": "Project2.html#motivation-and-context",
    "href": "Project2.html#motivation-and-context",
    "title": "Project2",
    "section": "",
    "text": "Write a few sentences about Encelia californica, Encelia farinosa, and the Fullerton Arboretum. You may also discuss what you learned about the iris dataset.\nWhy should someone care about being able to distinguish between these two species?"
  },
  {
    "objectID": "Project2.html#main-objective",
    "href": "Project2.html#main-objective",
    "title": "Project2",
    "section": "Main Objective",
    "text": "Main Objective\nIn your own words, describe the goal of this project."
  },
  {
    "objectID": "Project2.html#packages-used-in-this-analysis",
    "href": "Project2.html#packages-used-in-this-analysis",
    "title": "Project2",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\nlibrary(here)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(purrr)\nlibrary(yardstick)\nlibrary(tidyr)\n\n\n\n\nPackage\nUse\n\n\n\n\nhere\nto easily load and save data\n\n\nreadr\nto import the CSV file data\n\n\ndplyr\nto massage and summarize data\n\n\nggplot2\nto create nice-looking and informative graphs\n\n\nrsample\nto split data into training and test sets\n\n\npurrr\nto run the cross-validation\n\n\nyardstick\nto evalute the accuracy of the models\n\n\ntidyr\nto “pivot” the predictions data frame so that each row represents 1 model"
  },
  {
    "objectID": "Project2.html#design-and-data-collection",
    "href": "Project2.html#design-and-data-collection",
    "title": "Project2",
    "section": "Design and Data Collection",
    "text": "Design and Data Collection\nIn this section, describe how you collected the data. (If you weren’t in class that day, ask your classmates how the data was collected.)\nBriefly describe the limitations of your data collection method. What difficulties did you (or the class collectively) have collecting the data? What choices did you (or the class collectively) make during the data collection process that someone else might choose differently?"
  },
  {
    "objectID": "Project2.html#training-test-split",
    "href": "Project2.html#training-test-split",
    "title": "Project2",
    "section": "Training-Test Split",
    "text": "Training-Test Split\nThere isn’t much data massaging we need to do here, because we were very deliberate about how we set up our data sheet and how we recorded the data on it. However, you may need to do things like import the data and change the type of some variables.\nAt the end of this section, you should write code to randomly split the Encelia data into a training and test set and explain why a training and test set are useful/necessary for this objective."
  },
  {
    "objectID": "Project2.html#exploratory-data-analysis",
    "href": "Project2.html#exploratory-data-analysis",
    "title": "Project2",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExpand on the EDA you did in the Logistic Regression with Encelia activity. Explain what is going on in your graphs and summaries and how those insights relate to the models you will be building in the next section."
  },
  {
    "objectID": "Project2.html#modeling",
    "href": "Project2.html#modeling",
    "title": "Project2",
    "section": "Modeling",
    "text": "Modeling\nPropose several logistic regression models and use cross-validation to select a best model, following the steps in the “Cross-Validation (Part 3)” video and the “Model Selection for Logistic Regression” activity.\nExplain what your code is doing:\n\nWhat is logistic regression? Why are you doing it?\nWhy did you choose each model that you are considering?\nWhy are you using cross-validation? How does it work?\nWhich model are you selecting as the best model? Why?\n\nFit the selected “best” model on the training set and make predictions on the test set. Overall, how accurately is your model making predictions?"
  },
  {
    "objectID": "Project2.html#insights",
    "href": "Project2.html#insights",
    "title": "Project2",
    "section": "Insights",
    "text": "Insights\nThink about how you might visualize the model’s predictions and the accuracy of those predictions. Then, create and describe one or more visualizations in line with your ideas.\nWhich flowers (if any) were incorrectly predicted? Why do you suspect that they were incorrectly predicted?"
  },
  {
    "objectID": "Project1.html",
    "href": "Project1.html",
    "title": "Project1",
    "section": "",
    "text": "Analysis of the Relationship between Loan Availability and Local Rent"
  },
  {
    "objectID": "Project1.html#subject",
    "href": "Project1.html#subject",
    "title": "Project1",
    "section": "",
    "text": "Analysis of the Relationship between Loan Availability and Local Rent"
  },
  {
    "objectID": "Project1.html#main-objective",
    "href": "Project1.html#main-objective",
    "title": "Project1",
    "section": "Main Objective",
    "text": "Main Objective\nIt analyzes how high rents in certain areas affect loan approval rates and insolvency rates to provide insights into financial-real estate linkage risks and financial product design."
  },
  {
    "objectID": "Project1.html#packages-used-in-this-analysis",
    "href": "Project1.html#packages-used-in-this-analysis",
    "title": "Project1",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\n# Data Wrangling\nlibrary(tidyverse)      \n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)         \nlibrary(janitor)       \n\nWarning: package 'janitor' was built under R version 4.3.3\n\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(lubridate)     \n\n# Exploratory Data Analysis\nlibrary(ggplot2)        \nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.3.3\n\n\ncorrplot 0.95 loaded\n\nlibrary(reshape2)\n\n\nAttaching package: 'reshape2'\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nlibrary(skimr)          \n\n# Model Prediction\nlibrary(caret)          \n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(glmnet)         \n\nWarning: package 'glmnet' was built under R version 4.3.3\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.3.3\n\n\nrandomForest 4.7-1.2\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: 'randomForest'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nThe following object is masked from 'package:ggplot2':\n\n    margin"
  },
  {
    "objectID": "Project1.html#used-data",
    "href": "Project1.html#used-data",
    "title": "Project1",
    "section": "Used Data",
    "text": "Used Data\nFor this project, I will use three main data files:\n\nloans_OC.csv: Contains loan data from Orange County.\nSoCalRent1.csv and SoCalRent2.csv: Contain rental data from Southern California, including various regions.\n\nThese datasets will be combined and analyzed to explore the relationship between regional rental prices and loan approval outcomes."
  },
  {
    "objectID": "Project1.html#data-wrangling",
    "href": "Project1.html#data-wrangling",
    "title": "Project1",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n# Read data\nloans &lt;- read_csv(\"loans_OC.csv\") %&gt;% clean_names()\n\nRows: 24472 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): institution, census_tract, ethnicity, race, sex, residency_type, ci...\ndbl (9): loan_amount, property_value, interest_rate, total_loan_costs, incom...\nlgl (1): applicant_over_62\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrent1 &lt;- read_csv(\"SoCalRent1.csv\") %&gt;% clean_names()\n\nRows: 183 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, Type, Location\ndbl (4): Price, Beds, Baths, SqFt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrent2 &lt;- read_csv(\"SoCalRent2.csv\") %&gt;% clean_names()\n\nRows: 117 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, Type, Location\ndbl (4): Price, Beds, Baths, SqFt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Combine rent datasets\nrent &lt;- bind_rows(rent1, rent2)\n\nWhen looking at the data, there were missing values, so it was imputed and processed up to outliers.\nRemoves any row in loans or rent where 50% or more of the values are missing. Rows with too many missing values may not be useful for analysis, and imputing them could introduce bias or noise. It is safer to drop them before further processing.\n\n# Remove rows with too many missing values\nloans &lt;- loans %&gt;%\n  filter(rowSums(is.na(.)) / ncol(.) &lt; 0.5)\n\nrent &lt;- rent %&gt;%\n  filter(rowSums(is.na(.)) / ncol(.) &lt; 0.5)\n\n# Impute missing values\nloans &lt;- loans %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\nrent &lt;- rent %&gt;%\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\n# Identify and remove outliers (IQR method)\nremove_outliers &lt;- function(df, col) {\n  if (!col %in% names(df)) {\n    warning(paste(\"Column\", col, \"not found in dataframe.\"))\n    return(df)\n  }\n  \n  non_na_values &lt;- df[[col]][!is.na(df[[col]])]\n  \n  if (length(non_na_values) == 0) {\n    warning(paste(\"No non-NA values in column\", col))\n    return(df)\n  }\n  \n  Q1 &lt;- quantile(non_na_values, 0.25)\n  Q3 &lt;- quantile(non_na_values, 0.75)\n  IQR &lt;- Q3 - Q1\n\n  lower &lt;- Q1 - 1.5 * IQR\n  upper &lt;- Q3 + 1.5 * IQR\n  \n  df %&gt;%\n    filter(.data[[col]] &gt;= lower & .data[[col]] &lt;= upper)\n}\n\n\nloans &lt;- remove_outliers(loans, \"loan_amount\")\nrent &lt;- remove_outliers(rent, \"rent\")\n\nWarning in remove_outliers(rent, \"rent\"): Column rent not found in dataframe.\n\n# Inspect data\nskim(loans)\n\n\nData summary\n\n\nName\nloans\n\n\nNumber of rows\n22127\n\n\nNumber of columns\n18\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nlogical\n1\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ninstitution\n0\n1.00\n4\n40\n0\n73\n0\n\n\ncensus_tract\n113\n0.99\n6\n6\n0\n577\n0\n\n\nethnicity\n0\n1.00\n5\n22\n0\n3\n0\n\n\nrace\n0\n1.00\n5\n16\n0\n7\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n3\n0\n\n\nresidency_type\n0\n1.00\n17\n19\n0\n3\n0\n\n\ncity\n3470\n0.84\n4\n22\n0\n40\n0\n\n\naction\n0\n1.00\n8\n12\n0\n2\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\napplicant_over_62\n6\n1\n0.12\nFAL: 19515, TRU: 2606\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nloan_amount\n0\n1\n648605.10\n263547.59\n5000.00\n475000.00\n645000.00\n815000.00\n1345000.00\n▂▆▇▃▂\n\n\nproperty_value\n0\n1\n922739.98\n402922.44\n15000.00\n665000.00\n865000.00\n1125404.84\n5305000.00\n▇▃▁▁▁\n\n\ninterest_rate\n0\n1\n3.09\n0.63\n0.75\n2.81\n3.00\n3.20\n11.60\n▆▇▁▁▁\n\n\ntotal_loan_costs\n0\n1\n7463.89\n3979.26\n0.00\n5520.00\n7016.94\n7978.05\n57545.50\n▇▁▁▁▁\n\n\nincome\n0\n1\n194.04\n255.45\n-245.00\n109.00\n155.00\n230.00\n24160.00\n▇▁▁▁▁\n\n\ntract_population\n0\n1\n6104.30\n3397.67\n0.00\n4242.00\n5539.00\n7089.00\n22185.00\n▃▇▁▁▁\n\n\ntract_minority_population_percent\n0\n1\n49.38\n21.23\n0.00\n33.33\n45.79\n66.17\n99.68\n▂▇▆▅▂\n\n\ntract_to_msa_income_percentage\n0\n1\n113.54\n45.88\n0.00\n83.00\n117.00\n146.00\n289.00\n▂▇▇▁▁\n\n\ntract_housing_median_age\n0\n1\n34.35\n15.63\n0.00\n24.00\n39.00\n46.00\n74.00\n▃▃▇▆▁\n\n\n\n\nskim(rent)\n\n\nData summary\n\n\nName\nrent\n\n\nNumber of rows\n300\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncity\n0\n1\n4\n22\n0\n74\n0\n\n\ntype\n0\n1\n5\n5\n0\n2\n0\n\n\nlocation\n0\n1\n2\n2\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nprice\n0\n1\n3711.27\n1733.90\n950\n2800\n3395\n4000\n20000.0\n▇▁▁▁▁\n\n\nbeds\n0\n1\n3.00\n0.96\n1\n2\n3\n4\n6.0\n▆▇▅▁▁\n\n\nbaths\n0\n1\n2.29\n0.80\n1\n2\n2\n3\n6.5\n▇▆▁▁▁\n\n\nsq_ft\n0\n1\n1633.31\n726.99\n500\n1120\n1454\n1968\n6361.0\n▇▅▁▁▁\n\n\n\n\n\n\n# Check missing values\nloans %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 × 18\n  institution census_tract ethnicity  race   sex residency_type loan_amount\n        &lt;int&gt;        &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;       &lt;int&gt;\n1           0          113         0     0     0              0           0\n# ℹ 11 more variables: property_value &lt;int&gt;, interest_rate &lt;int&gt;,\n#   total_loan_costs &lt;int&gt;, income &lt;int&gt;, applicant_over_62 &lt;int&gt;,\n#   tract_population &lt;int&gt;, tract_minority_population_percent &lt;int&gt;,\n#   tract_to_msa_income_percentage &lt;int&gt;, tract_housing_median_age &lt;int&gt;,\n#   city &lt;int&gt;, action &lt;int&gt;\n\nrent %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\n# A tibble: 1 × 7\n   city price  beds baths sq_ft  type location\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n1     0     0     0     0     0     0        0\n\n\nMissing values for non-dimensional variables such as census_tract were not imputed. In addition, since the analysis does not use the variable for modeling or calculation, we decided that it doesn’t matter if there are missing values.\nThis code transforms two separate datasets (loan and rent) into aggregated city-level summaries and merges them into a single dataset. This merged dataset is ready for exploratory data analysis (EDA) and modeling to study the relationship between loan approval rates and rental market factors across cities.\n\n# Aggregate loans data by City\nloans_city_summary &lt;- loans %&gt;%\n  group_by(city) %&gt;%\n  summarise(\n    approval_rate = mean(action == \"Approved\", na.rm = TRUE),\n    avg_loan_amount = mean(loan_amount, na.rm = TRUE),\n    avg_income = mean(income, na.rm = TRUE),\n    count_loans = n()\n  ) %&gt;%\n  ungroup()\n\n\n# Aggregate rent data by City\nrent_summary &lt;- rent %&gt;%\n  group_by(city) %&gt;%\n  summarise(\n    avg_rent = mean(price, na.rm = TRUE),\n    avg_sqft = mean(sq_ft, na.rm = TRUE),\n    count_rentals = n()\n  ) %&gt;%\n  ungroup()\n\n\n# merge (inner join: only common city)\ncombined &lt;- inner_join(loans_city_summary, rent_summary, by = \"city\")\n\nprint(head(combined))\n\n# A tibble: 6 × 8\n  city    approval_rate avg_loan_amount avg_income count_loans avg_rent avg_sqft\n  &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;      &lt;dbl&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Aliso …         0.944         586512.       168.         516    3420     1252.\n2 Anaheim         0.861         578890.       160.        1789    3716.    1227.\n3 Brea            0.821         505247.       151.         324    2575     1280 \n4 Buena …         0.899         554760.       143.         416    3125     1439 \n5 Costa …         0.883         741845.       243.         580    4025.    1338.\n6 Cypress         0.903         595583.       152.         309    5600     1724 \n# ℹ 1 more variable: count_rentals &lt;int&gt;"
  },
  {
    "objectID": "Project1.html#explore-combined-data",
    "href": "Project1.html#explore-combined-data",
    "title": "Project1",
    "section": "Explore combined data",
    "text": "Explore combined data\n\nskim(combined)\n\n\nData summary\n\n\nName\ncombined\n\n\nNumber of rows\n30\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncity\n0\n1\n4\n22\n0\n30\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\napproval_rate\n0\n1\n0.88\n0.05\n0.72\n0.86\n0.89\n0.91\n0.95\n▁▁▅▇▆\n\n\navg_loan_amount\n0\n1\n635642.76\n103182.04\n399558.40\n580795.74\n639746.87\n697175.06\n933043.48\n▂▅▇▂▁\n\n\navg_income\n0\n1\n188.56\n48.29\n113.81\n157.34\n181.10\n211.95\n305.88\n▃▇▃▁▂\n\n\ncount_loans\n0\n1\n559.00\n402.55\n46.00\n291.00\n470.50\n751.25\n1789.00\n▇▅▃▁▁\n\n\navg_rent\n0\n1\n3909.98\n1242.70\n1550.00\n3031.25\n3707.78\n4332.92\n7030.57\n▁▇▅▂▁\n\n\navg_sqft\n0\n1\n1568.45\n669.47\n930.00\n1137.96\n1309.12\n1831.00\n4300.00\n▇▅▁▁▁\n\n\ncount_rentals\n0\n1\n4.97\n5.02\n1.00\n1.25\n3.00\n7.00\n24.00\n▇▂▁▁▁"
  },
  {
    "objectID": "Project1.html#eda-with-visualization",
    "href": "Project1.html#eda-with-visualization",
    "title": "Project1",
    "section": "EDA with Visualization",
    "text": "EDA with Visualization\nThese three visualizations work together to provide: - A matrix view of correlations between key variables. - A focused scatter plot for the relationship of rent vs approval rate. - A summary of the approval rate distribution across the dataset.\n👉 They support exploratory data analysis (EDA) by uncovering patterns and potential relationships before modeling.\n\n# correlation matrix\ncor_matrix &lt;- combined %&gt;%\n  select(approval_rate, avg_rent, avg_loan_amount, avg_income, avg_sqft) %&gt;%\n  cor(use = \"complete.obs\")\n\ncor_melted &lt;- melt(cor_matrix)\n\nggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +\n  geom_tile() +\n  geom_text(aes(label = round(value, 2)), color = \"white\", size = 4) +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0) +\n  labs(title = \"Correlation Heatmap\",\n       x = \"\",\n       y = \"\",\n       fill = \"Correlation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Scatter plot: Average rent vs approval rate\nggplot(combined, aes(x = avg_rent, y = approval_rate)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Average Rent vs Loan Approval Rate\",\n       x = \"Average Rent\",\n       y = \"Approval Rate\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# 3. Distribution of approval_rate\nggplot(combined, aes(x = approval_rate)) +\n  geom_histogram(bins = 20, fill = \"skyblue\") +\n  labs(title = \"Distribution of Loan Approval Rate\", x = \"Approval Rate\", y = \"Count\")\n\n\n\n\n\n\n\n\n👉 From these results, it appears that the loan approval rate is relatively high across most cities and shows weak correlation with average rent, average income, and property size. However, strong multicollinearity is observed among the predictor variables.\n👉 Given these findings, I plan to proceed with regression modeling to formally test the statistical significance and predictive power of average rent, income, and loan amount on the approval rate, despite the low correlations observed.\n👉 I also intend to explore alternative models such as regularized regression (LASSO) to address multicollinearity and assess variable importance, and non-linear models (e.g., random forest) to capture any non-linear effects that may not be visible in the scatter plot.\nThe exploratory data analysis shows weak correlations between loan approval rate and predictors such as average rent and income, while strong correlations are present among the predictors themselves. Therefore, we plan to use linear regression, LASSO, and random forest models to further investigate the relationship. Perhaps the predictive performance of the random forest model, which is less affected by multicollinearity, is expected to be the best."
  },
  {
    "objectID": "Project1.html#predictive-modeling",
    "href": "Project1.html#predictive-modeling",
    "title": "Project1",
    "section": "Predictive Modeling",
    "text": "Predictive Modeling\n\n# Select key variables\nmodel_data &lt;- combined %&gt;%\n  select(approval_rate, avg_rent, avg_income, avg_sqft) %&gt;%\n  na.omit()  # remove missing values\n\n# Split into training (80%) and testing (20%) sets\nset.seed(123)\ntrain_index &lt;- createDataPartition(model_data$approval_rate, p = 0.8, list = FALSE)\ntrain_data &lt;- model_data[train_index, ]\ntest_data &lt;- model_data[-train_index, ]\n\n\n# Set up cross-validation\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 5,\n  summaryFunction = defaultSummary\n)\n\n\n# Load libraries\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.3.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.3.3\n\n\nWarning: package 'dials' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.3\n\n\nWarning: package 'modeldata' was built under R version 4.3.3\n\n\nWarning: package 'parsnip' was built under R version 4.3.3\n\n\nWarning: package 'recipes' was built under R version 4.3.3\n\n\nWarning: package 'tune' was built under R version 4.3.3\n\n\nWarning: package 'workflows' was built under R version 4.3.3\n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ randomForest::combine()  masks dplyr::combine()\n✖ scales::discard()        masks purrr::discard()\n✖ Matrix::expand()         masks tidyr::expand()\n✖ dplyr::filter()          masks stats::filter()\n✖ recipes::fixed()         masks stringr::fixed()\n✖ dplyr::lag()             masks stats::lag()\n✖ caret::lift()            masks purrr::lift()\n✖ randomForest::margin()   masks ggplot2::margin()\n✖ Matrix::pack()           masks tidyr::pack()\n✖ yardstick::precision()   masks caret::precision()\n✖ yardstick::recall()      masks caret::recall()\n✖ yardstick::sensitivity() masks caret::sensitivity()\n✖ yardstick::spec()        masks readr::spec()\n✖ yardstick::specificity() masks caret::specificity()\n✖ recipes::step()          masks stats::step()\n✖ Matrix::unpack()         masks tidyr::unpack()\n✖ recipes::update()        masks Matrix::update(), stats::update()\n\n# 1️⃣ Recipe\nloan_recipe &lt;- recipe(approval_rate ~ ., data = train_data) %&gt;%\n  step_normalize(all_predictors())\n\n# 2️⃣ Model specifications\nlm_spec &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\")\n\nrf_spec &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nlasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%  # mixture=1 for LASSO\n  set_engine(\"glmnet\")\n\n# 3️⃣ Workflow\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(lm_spec)\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(rf_spec)\n\nlasso_wf &lt;- workflow() %&gt;%\n  add_recipe(loan_recipe) %&gt;%\n  add_model(lasso_spec)\n\n# 4️⃣ Cross-validation\nset.seed(123)\ncv_folds &lt;- vfold_cv(train_data, v = 5)\n\n# 5️⃣ Fit models\nlm_res &lt;- lm_wf %&gt;% fit_resamples(resamples = cv_folds, metrics = metric_set(rmse, rsq))\nrf_res &lt;- rf_wf %&gt;% fit_resamples(resamples = cv_folds, metrics = metric_set(rmse, rsq))\n\nWarning: package 'ranger' was built under R version 4.3.3\n\nlasso_res &lt;- lasso_wf %&gt;% tune_grid(\n  resamples = cv_folds,\n  grid = grid_regular(penalty(), levels = 10),\n  metrics = metric_set(rmse, rsq)\n)\n\n→ A | warning: A correlation computation is required, but `estimate` is constant and has 0\n               standard deviation, resulting in a divide by 0 error. `NA` will be returned.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x5\n\n\n\n\n# 6️⃣ Collect metrics\ncollect_metrics(lm_res)\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0620     5  0.0162 Preprocessor1_Model1\n2 rsq     standard   0.115      5  0.0776 Preprocessor1_Model1\n\ncollect_metrics(rf_res)\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0454     5 0.00842 Preprocessor1_Model1\n2 rsq     standard   0.181      5 0.0639  Preprocessor1_Model1\n\ncollect_metrics(lasso_res)\n\n# A tibble: 20 × 7\n         penalty .metric .estimator     mean     n std_err .config              \n           &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 0.0000000001  rmse    standard     0.0618     5  0.0162 Preprocessor1_Model01\n 2 0.0000000001  rsq     standard     0.116      5  0.0777 Preprocessor1_Model01\n 3 0.00000000129 rmse    standard     0.0618     5  0.0162 Preprocessor1_Model02\n 4 0.00000000129 rsq     standard     0.116      5  0.0777 Preprocessor1_Model02\n 5 0.0000000167  rmse    standard     0.0618     5  0.0162 Preprocessor1_Model03\n 6 0.0000000167  rsq     standard     0.116      5  0.0777 Preprocessor1_Model03\n 7 0.000000215   rmse    standard     0.0618     5  0.0162 Preprocessor1_Model04\n 8 0.000000215   rsq     standard     0.116      5  0.0777 Preprocessor1_Model04\n 9 0.00000278    rmse    standard     0.0618     5  0.0162 Preprocessor1_Model05\n10 0.00000278    rsq     standard     0.116      5  0.0777 Preprocessor1_Model05\n11 0.0000359     rmse    standard     0.0618     5  0.0162 Preprocessor1_Model06\n12 0.0000359     rsq     standard     0.117      5  0.0776 Preprocessor1_Model06\n13 0.000464      rmse    standard     0.0602     5  0.0155 Preprocessor1_Model07\n14 0.000464      rsq     standard     0.122      5  0.0764 Preprocessor1_Model07\n15 0.00599       rmse    standard     0.0498     5  0.0115 Preprocessor1_Model08\n16 0.00599       rsq     standard     0.276      2  0.173  Preprocessor1_Model08\n17 0.0774        rmse    standard     0.0449     5  0.0113 Preprocessor1_Model09\n18 0.0774        rsq     standard   NaN          0 NA      Preprocessor1_Model09\n19 1             rmse    standard     0.0449     5  0.0113 Preprocessor1_Model10\n20 1             rsq     standard   NaN          0 NA      Preprocessor1_Model10\n\nfinal_lm &lt;- lm_wf %&gt;% fit(data = train_data)\nfinal_rf &lt;- rf_wf %&gt;% fit(data = train_data)\nfinal_lasso &lt;- lasso_wf %&gt;%\n  finalize_workflow(select_best(lasso_res)) %&gt;%  # lasso는 best tuning 값 사용\n  fit(data = train_data)\n\nWarning in select_best(lasso_res): No value of `metric` was given; \"rmse\" will\nbe used.\n\n\n\n# Make predictions and evaluate performance\nlm_pred &lt;- predict(final_lm, new_data = test_data)\nrf_pred &lt;- predict(final_rf, new_data = test_data)\nlasso_pred &lt;- predict(final_lasso, new_data = test_data)\n\nlm_perf &lt;- postResample(pred = lm_pred, obs = test_data$approval_rate)\nrf_perf &lt;- postResample(pred = rf_pred, obs = test_data$approval_rate)\nlasso_perf &lt;- postResample(pred = lasso_pred, obs = test_data$approval_rate)\n\n\n# Compare model performance\nresults &lt;- data.frame(\n  Model = c(\"Linear Regression\", \"Random Forest\", \"LASSO\"),\n  RMSE = c(lm_perf[\"RMSE\"], rf_perf[\"RMSE\"], lasso_perf[\"RMSE\"]),\n  Rsquared = c(lm_perf[\"Rsquared\"], rf_perf[\"Rsquared\"], lasso_perf[\"Rsquared\"])\n)\n\nprint(\"Model Performance Comparison:\")\n\n[1] \"Model Performance Comparison:\"\n\nprint(results)\n\n              Model       RMSE  Rsquared\n1 Linear Regression 0.03938614 0.3498441\n2     Random Forest 0.03139006 0.3886215\n3             LASSO 0.03806624        NA\n\n\nAs expected, the R squared value showed the best performance of the random forest model, which could be selected as the final model.\n\n# Plot variable importance (Random Forest)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nvip(final_rf)\n\n\n\n\n\n\n\n\nThe variable that most influenced the prediction was identified as avg_income."
  },
  {
    "objectID": "Project1.html#significance-of-the-project",
    "href": "Project1.html#significance-of-the-project",
    "title": "Project1",
    "section": "Significance of the Project",
    "text": "Significance of the Project\nThis project integrates loan data and rental market data at the city level to explore potential relationships between loan approval rates and local housing characteristics.By combining and analyzing these datasets, we aim to uncover patterns that may not be visible from loan data or rental data alone.\nThrough data cleaning, transformation, exploratory data analysis (EDA), and predictive modeling, the project demonstrates a complete data science pipeline from raw data to actionable insights."
  },
  {
    "objectID": "Project1.html#key-insights-breaking-points",
    "href": "Project1.html#key-insights-breaking-points",
    "title": "Project1",
    "section": "Key Insights & Breaking points",
    "text": "Key Insights & Breaking points\nIt was discovered that average income was the predictor that had the greatest impact on the loan approval rate.\nHowever, it was difficult to maximize the model’s performance due to the small number of variables and data, suggesting that additional factors such as credit scores and debt ratios were needed. In addition, if the multicollinearity problem, which reveals a strong correlation between predictors, has been solved, better performance can be expected in the linear regression model."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSUF_DS",
    "section": "",
    "text": "Hello everyone. I’m Junho Kook, an exchange student from South Korea. I did my best to prepare it even though it has linguistic barriers and I’m new to the R project."
  }
]